

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>&lt;no title&gt; &mdash; GWPopulation 0.6.3 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="gwpopulation.vt.ResamplingVT" href="_autosummary/gwpopulation.vt.ResamplingVT.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> GWPopulation
          

          
          </a>

          
            
            
              <div class="version">
                0.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/gwpopulation.models.html">gwpopulation.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/gwpopulation.conversions.html">gwpopulation.conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/gwpopulation.cupy_utils.html">gwpopulation.cupy_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/gwpopulation.hyperpe.html">gwpopulation.hyperpe</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/gwpopulation.utils.html">gwpopulation.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/gwpopulation.vt.html">gwpopulation.vt</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GWPopulation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>&lt;no title&gt;</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/GWTC1.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><p>“nbformat”: 4,
“nbformat_minor”: 0,
“metadata”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“colab”: {</dt><dd><p>“name”: “GWTC1.ipynb”,
“version”: “0.3.2”,
“provenance”: [],
“collapsed_sections”: [],
“include_colab_link”: true</p>
</dd>
</dl>
<p>},
“kernelspec”: {</p>
<blockquote>
<div><p>“name”: “python3”,
“display_name”: “Python 3”</p>
</div></blockquote>
<p>},
“accelerator”: “GPU”,
“pycharm”: {</p>
<blockquote>
<div><dl>
<dt>“stem_cell”: {</dt><dd><p>“cell_type”: “raw”,
“source”: [],
“metadata”: {</p>
<blockquote>
<div><p>“collapsed”: false</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“cells”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {</p>
<blockquote>
<div><p>“id”: “view-in-github”,
“colab_type”: “text”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“[![Open in Colab](<a class="reference external" href="https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ColmTalbot/gwpopulation/blob/master/examples/GWTC1.ipynb">https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ColmTalbot/gwpopulation/blob/master/examples/GWTC1.ipynb</a>)”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “kiawJMuzaMqA”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“n”,
“# Population Inference on GWTC-1n”,
“n”,
“The first gravitational-wave transient catalog [&quot;GWTC-1&quot;](<a class="reference external" href="https://arxiv.org/abs/1811.12907">https://arxiv.org/abs/1811.12907</a>) includes all compact binary coalescences observed during Advanced LIGO/Virgo’s first and second observing runs.n”,
“n”,
“<cite>GWPopulation</cite> builds upon [bilby](git.ligo.org/lscsoft/bilby) ([arXiv:1811.02042](https://arxiv.org/abs/1811.02042)) to provide simple, modular, user-friendly, population inference.n”,
“n”,
“Currently implemented models include:n”,
“n”,
“- One and two component mass distributions in primary mass and mass ratio, e.g., Talbot &amp; Thrane (2018) ([arXiv:1801:02699](https://arxiv.org/abs/1801.02699)), Fishbach &amp; Holz (2018) ([arXiv:1709.08584](https://arxiv.org/abs/1709.08584)).n”,
“- The same mass distributions but independent but identically distributed primary and secondary.n”,
“- Half-Gaussian + isotropic spin tilt distribution from Talbot &amp; Thrane (2017) ([arXiv:1704.08370](https://arxiv.org/abs/1704.08370)).n”,
“- Beta spin magnitude distribution from Wysocki+ (2018) ([arXiv:1805:06442](https://arxiv.org/abs/1805.06442)).n”,
“- Each of these are also available with independent but identically distributed spins.n”,
“- Redshift evolution model as in Fishbach+ (2018) ([arXiv:1805.10270](https://arxiv.org/abs/1805.10270)).n”,
“- More to come and any contributions welcome…n”,
“n”,
“For more information see the [git repository](https://github.com/ColmTalbot/gwpopulation), [documentation](https://colmtalbot.github.io/gwpopulation/).n”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “U6RH_xfNbBb3”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Install some packagesn”,
“n”,
“- <cite>gwpopulation</cite> has the population model code.n”,
“- <cite>cupy</cite> allows use to leverage the GPU.n”,
“n”,
“If you’re using colab.research.google.com you will want to choose a GPU-accelerated runtime.n”,
“n”,
“&quot;runtime&quot;-&gt;&quot;change runtime type&quot;-&gt;&quot;Hardware accelerator = GPU&quot;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “WT13XqcsZoie”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“!pip install gwpopulation”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “1tjorhzLaoU2”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“!pip install cupy”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “rxjmzikYa0bb”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Get the datan”,
“n”,
“Pull the posterior samples for each of the events from the LIGO dcc.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “GXZpNd3cZ3hF”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“!wget <a class="reference external" href="https://dcc.ligo.org/public/0157/P1800370/002/GWTC-1_sample_release.tar.gzn">https://dcc.ligo.org/public/0157/P1800370/002/GWTC-1_sample_release.tar.gzn</a>”,
“!tar -xvzf GWTC-1_sample_release.tar.gz”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “NLEgW_zrbNPw”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Importsn”,
“n”,
“Import the packages required for the script.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “7zJiHR7rayRR”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“%pylab inlinen”,
“n”,
“import h5pyn”,
“n”,
“import pandas as pdn”,
“from scipy.interpolate import interp1dn”,
“from astropy import cosmology, unitsn”,
“n”,
“import bilby as bbn”,
“from bilby.core.prior import LogUniform, PriorDict, Uniformn”,
“from bilby.hyper.model import Modeln”,
“import gwpopulation as gwpopn”,
“xp = gwpop.cupy_utils.xp”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “hm3_uaQRbXmS”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Load posteriorsn”,
“n”,
“We’re using the posteriors from the GWTC-1 data release.n”,
“n”,
“We need to change the names of the parameters to make them work with the code.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “BojmLvpxbYwM”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“parameter_translator = dict(n”,
”    mass_1_det=’m1_detector_frame_Msun’,n”,
”    mass_2_det=’m2_detector_frame_Msun’,n”,
”    luminosity_distance=’luminosity_distance_Mpc’,n”,
”    a_1=’spin1’,n”,
”    a_2=’spin2’,n”,
”    cos_tilt_1=’costilt1’,n”,
”    cos_tilt_2=’costilt2’)n”,
“n”,
“posteriors = list()n”,
“priors = list()n”,
“n”,
“file_str = ‘./GWTC-1_sample_release/GW{}_GWTC-1.hdf5’n”,
“n”,
“events = [‘150914’, ‘151012’, ‘151226’, ‘170104’, ‘170608’,n”,
”          ‘170729’, ‘170809’, ‘170814’, ‘170818’, ‘170823’]n”,
“for event in events:n”,
”    _posterior = pd.DataFrame()n”,
”    _prior = pd.DataFrame()n”,
”    with h5py.File(file_str.format(event)) as ff:n”,
”        for my_key, gwtc_key in parameter_translator.items():n”,
”            _posterior[my_key] = ff[‘IMRPhenomPv2_posterior’][gwtc_key]n”,
”            _prior[my_key] = ff[‘prior’][gwtc_key]n”,
”    posteriors.append(_posterior)n”,
”    priors.append(_prior)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “ol2czCPkblx6”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“luminosity_distances = np.linspace(1, 10000, 1000)n”,
“redshifts = np.array([n”,
”    cosmology.z_at_value(n”,
”        cosmology.Planck15.luminosity_distance, dl * units.Mpc)n”,
”    for dl in luminosity_distances])n”,
“dl_to_z = interp1d(luminosity_distances, redshifts)n”,
“n”,
“luminosity_prior = luminosity_distances ** 2n”,
“n”,
“dz_ddl = np.gradient(redshifts, luminosity_distances)n”,
“n”,
“redshift_prior = interp1d(n”,
”    redshifts, luminosity_prior / dz_ddl / (1 + redshifts))”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “9zlAGxTxRUIn”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Add some weights to posteriorn”,
“n”,
“Make sure the posterior <cite>DataFrames</cite> contain the appropriate quantities.n”,
“n”,
“We could include a <cite>prior</cite> column, this is the prior used in the initial sampling stage.n”,
“This is used to weight the samples in the likelihood.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “hTqr-NvTbn4c”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“for posterior in posteriors:n”,
”    posterior[‘redshift’] = dl_to_z(posterior[‘luminosity_distance’])n”,
”    posterior[‘mass_1’] = posterior[‘mass_1_det’] / (1 + posterior[‘redshift’])n”,
”    posterior[‘mass_2’] = posterior[‘mass_2_det’] / (1 + posterior[‘redshift’])n”,
”    posterior[‘mass_ratio’] = posterior[‘mass_2’] / posterior[‘mass_1’]”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “Bx1xdvjubhmA”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Specify the modeln”,
“n”,
“Choose which population models we want to use. n”,
“n”,
“For the mass distribution we use n”,
“n”,
“<cite>gwpopulation.models.mass.two_component_primary_mass_ratio</cite>.n”,
“n”,
“This is a powerlaw + Gaussian mass distribution with powerlaw mass ratio distribution.n”,
“n”,
“For spins we usen”,
“n”,
“<cite>gwpopulation.models.spin.iid_spin</cite>n”,
“n”,
“Where the spins of the two black holes are independently and identically distirbuted with a beta distribution for the magnitude and an isotropic + half-Gaussian for the cosine tilts.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “rHspMjv-bpyZ”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“model = Model([gwpop.models.mass.two_component_primary_mass_ratio])”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “7NwQL52xbrxr”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Selection effectsn”,
“n”,
“Gravitational-wave surveys suffer from Malmquist bias.n”,
“n”,
“In order to measure the true, astrophysical, distribution we must include a term to account for this in our population analyses.n”,
“n”,
“The way the likelihood is structured, this can be any object that evaluates to give the observed spactime volume as a function of the population parameters.n”,
“n”,
“We define classes so that various bits of metadata can be stored.n”,
“n”,
“The data for calculating this is not easily available.n”,
“We use a very rough toy model to get the general scaling for the primary mass, $VT(m) \sim m^{1.6}$.n”,
“This value was chosen to get a decent agreement with the more complex model.n”,
“n”,
“<strong>I do not recommend using this toy function for science.</strong>”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “wmgJOa57bttM”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“masses = xp.linspace(3, 100, 1000)n”,
“vts = masses**1.6n”,
“n”,
“def toy_vt_calculator(kwargs):n”,
”    params = {key: kwargs[key] for key in n”,
”              [‘alpha’, ‘mmin’, ‘mmax’, ‘lam’, ‘mpp’, ‘sigpp’]}n”,
”    p_m = gwpop.models.mass.two_component_single(n”,
”        masses, <a href="#id1"><span class="problematic" id="id2">**</span></a>params)n”,
”    return gwpop.cupy_utils.trapz(p_m * vts, masses)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “LsHr0RCCb18B”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Define the likelihoodn”,
“n”,
“The <cite>HyperparameterLikelihood</cite> marginalises over the local merger rate, with a uniform-in-log prior.n”,
“n”,
“To also estimate the rate use the <cite>RateLikelilhood</cite> (see further on in the notebook).n”,
“n”,
“We provide:n”,
“- <cite>posteriors</cite>: a list of <cite>pandas</cite> DataFramesn”,
“- <cite>hyper_prior</cite>: our population model, as defined aboven”,
“- <cite>selection_function</cite>: anything which evaluates the selection functionn”,
“n”,
“We can also provide:n”,
“- <cite>conversion_function</cite>: this converts between the parameters we sample in and those needed by the model, e.g., for sampling in the mean and variance of the beta distributionn”,
“- <cite>max_samples</cite>: the maximum number of samples to use from each posterior, this defaults to the length of the shortest posteriorn”,
“n”,
“We may get a warning telling us <cite>cupy</cite> is not available and so <cite>numpy</cite> is for the likelihood evaluation.n”,
“This will go away if you have a GPU and <cite>cupy</cite> installed.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “0NhriPjTbzT7”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“fast_likelihood = gwpop.hyperpe.HyperparameterLikelihood(n”,
”    posteriors=posteriors, hyper_prior=model,n”,
”    selection_function=toy_vt_calculator)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “6HuGzAh1b7FQ”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Define the priorn”,
“n”,
“This is the standard method to define the prior distribution within <cite>bilby</cite>.n”,
“n”,
“The labels are used in plotting.n”,
“n”,
“Numbers are converted to delta function priors and are not sampled.n”,
“n”,
“There are many other distributions available, see the code/documentation for a full list.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “7pD90QeEb9aV”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“fast_priors = PriorDict()n”,
“n”,
“# massn”,
“fast_priors[‘alpha’] = Uniform(minimum=-2, maximum=4, latex_label=’$\\alpha$’)n”,
“fast_priors[‘beta’] = Uniform(minimum=-4, maximum=12, latex_label=’$\\beta$’)n”,
“fast_priors[‘mmin’] = Uniform(minimum=5, maximum=10, latex_label=’$m_{\\min}$’)n”,
“fast_priors[‘mmax’] = Uniform(minimum=20, maximum=60, latex_label=’$m_{\\max}$’)n”,
“fast_priors[‘lam’] = Uniform(minimum=0, maximum=1, latex_label=’$\\lambda_{m}$’)n”,
“fast_priors[‘mpp’] = Uniform(minimum=10, maximum=50, latex_label=’$\\mu_{m}$’)n”,
“fast_priors[‘sigpp’] = Uniform(minimum=0, maximum=10, latex_label=’$\\sigma_{m}$’)n”,
“# spinn”,
“fast_priors[‘amax’] = 1n”,
“fast_priors[‘alpha_chi’] = Uniform(minimum=-4, maximum=12, latex_label=’$\\alpha_{\\chi}$’)n”,
“fast_priors[‘beta_chi’] = Uniform(minimum=-4, maximum=12, latex_label=’$\\beta_{\\chi}$’)n”,
“fast_priors[‘xi_spin’] = Uniform(minimum=0, maximum=1, latex_label=’$\\xi$’)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “hOXy6gHmcAVf”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Run the samplern”,
“n”,
“We’ll use the sampler <cite>dynesty</cite> and use a small number of live points to reduce the runtime.n”,
“n”,
“This is painfully slow without using the GPU version.n”,
“If you have a GPU it will just work.n”,
“n”,
“Other samplers are available, <cite>cpnest</cite> gave the best results for the O1+O2 data, however it isn’t currently compatible with the GPU likelihood.n”,
“n”,
“<cite>bilby</cite> times a single likelihood evaluation before beginning the runn”,
“n”,
“We do a call before running to sampler as <cite>cupy</cite> compiles kernels the first time they are evaluated and so the estimate of the evaluation time would be off.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “EFGmgznvcC4s”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“fast_likelihood.parameters.update(fast_priors.sample())n”,
“fast_likelihood.log_likelihood_ratio()n”,
“n”,
“fast_result = bb.run_sampler(n”,
”    likelihood=fast_likelihood, priors=fast_priors, sampler=’dynesty’,n”,
”    nlive=100, label=’fast’)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “vSrM3Dy1zsKL”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“fast_result.plot_corner(save=False)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “hBfS17v47-zu”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Define a new modeln”,
“n”,
“### Let’s define a new population model for BNS. n”,
“n”,
“Just as an example we’ll use a Gaussian distribution bounded between $[1 M_{\odot}, 2 M_{\odot}]$.n”,
“n”,
“$$p(m_1, m_2) = N \exp \left(- \frac{\left((m_1 - \mu)^2 + (m_2 - \mu)^2\right)}{2 \sigma^2}\right) \quad : \quad 1 \leq m_2 \leq m_1 \leq 2$$n”,
“n”,
“We see that this function takes three arguments:n”,
“- <cite>dataset</cite>: this is common to all of the population models in <cite>gwpopulation</cite>, it is a dictionary containing the data to be evaluated, here it is assumed to contain entries for <cite>mass_1</cite> and <cite>mass_2</cite>, the _source-<a href="#id9"><span class="problematic" id="id10">frame_</span></a> masses.n”,
“- <cite>mu_bns</cite>: the peak of the bns mass distribution.n”,
“- <cite>sigma_bns</cite>: the width of the bns mass distribution.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “qRKha-Mv8Zav”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“def truncated_gaussian_primary_secondary_identical(dataset, mu_bns, sigma_bns):n”,
”    prob = gwpop.utils.truncnorm(n”,
”        dataset[‘mass_1’], mu=mu_bns, sigma=sigma_bns, low=1, high=2)n”,
”    prob <a href="#id3"><span class="problematic" id="id4">*</span></a>= gwpop.utils.truncnorm(n”,
”        dataset[‘mass_2’], mu=mu_bns, sigma=sigma_bns, low=1, high=2)n”,
”    prob <a href="#id5"><span class="problematic" id="id6">*</span></a>= (dataset[‘mass_1’] &gt;= dataset[‘mass_2’])n”,
”    prob <a href="#id7"><span class="problematic" id="id8">*</span></a>= 2n”,
”    return prob”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “IflaTL8l9TJQ”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Load GW170817 posteriorn”,
“n”,
“This is just the same as above.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “ubZz578B9ATE”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“posterior = pd.DataFrame()n”,
“prior = pd.DataFrame()n”,
“with h5py.File(‘./GWTC-1_sample_release/GW170817_GWTC-1.hdf5’) as ff:n”,
”    for my_key, gwtc_key in parameter_translator.items():n”,
”        try:n”,
”            posterior[my_key] = ff[‘IMRPhenomPv2NRT_lowSpin_posterior’][gwtc_key]n”,
”            prior[my_key] = ff[‘IMRPhenomPv2NRT_lowSpin_prior’][gwtc_key]n”,
”        except ValueError:n”,
”            passn”,
”        n”,
“posterior[‘redshift’] = dl_to_z(posterior[‘luminosity_distance’])n”,
“posterior[‘mass_1’] = posterior[‘mass_1_det’] / (1 + posterior[‘redshift’])n”,
“posterior[‘mass_2’] = posterior[‘mass_2_det’] / (1 + posterior[‘redshift’])”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “ktT2Ydiw9Yak”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Define the new likelihoodn”,
“n”,
“We use the same likelihood as before.n”,
“n”,
“_Note_:n”,
“- This time we cast our posterior to a list while creating the likelihood.n”,
“- We pass the function rather than a <cite>Model</cite> object as before, <cite>bilby</cite> will turn this into a <cite>Model</cite> for internal use.n”,
“- We’ve removed the selection and conversion functions as they aren’t needed here (yes, a selection function is techinically needed).”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “0xqYdOKV9F1E”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“bns_likelihood = gwpop.hyperpe.HyperparameterLikelihood(n”,
”    posteriors=[posterior],n”,
”    hyper_prior=truncated_gaussian_primary_secondary_identical)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “iGHtErVA9hBb”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Define the new priorn”,
“n”,
“Just as before.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “gn_vPWIW9MED”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“bns_priors = PriorDict()n”,
“bns_priors[‘mu_bns’] = Uniform(minimum=1, maximum=2, latex_label=’$\\mu_{bns}$’)n”,
“bns_priors[‘sigma_bns’] = LogUniform(minimum=1e-2, maximum=1, latex_label=’$\\sigma_{bns}$’)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “d_gwpGQi9e0M”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“bns_likelihood.parameters.update(bns_priors.sample())n”,
“bns_likelihood.log_likelihood_ratio()n”,
“n”,
“bns_result = bb.run_sampler(n”,
”    likelihood=bns_likelihood, priors=bns_priors, sampler=’dynesty’,n”,
”    nlive=1000)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “Y1O73fzb9t1S”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“bns_result.plot_corner(save=False)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “mxXt8coXANxX”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Do it alln”,
“n”,
“Let’s put together a run with models for the mass, spin and redshift distributions.n”,
“n”,
“<strong>This will not give sensible answers because VT is not estimated.</strong>n”,
“n”,
“The data for VT estimation isn’t available in this notebook.n”,
“n”,
“Note that the redshift model is a class and so is called slightly differently.n”,
“This is to enable caching of expensive data internally.n”,
“To call this <cite>bilby&gt;=0.4.2</cite> is required.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “LTq6eP5qAgLm”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“full_model = Model([n”,
”    gwpop.models.mass.two_component_primary_mass_ratio,n”,
”    gwpop.models.spin.iid_spin_magnitude_beta,n”,
”    gwpop.models.spin.independent_spin_orientation_gaussian_isotropic,n”,
”    gwpop.models.redshift.PowerLawRedshift()])”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “<a href="#id11"><span class="problematic" id="id12">T4Ize_dKRtC_</span></a>”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Update sampling priorn”,
“n”,
“We need to update the sampling prior to account for the new redshift evolution model.n”,
“n”,
“Fortunately, we defined an interpolant for this earlier.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “7i0WSBDZRunm”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“for posterior in posteriors:n”,
”    posterior[‘prior’] = redshift_prior(posterior[‘redshift’])”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “5JxwG1xNSJ_9”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Likelihoodn”,
“n”,
“We use a different likelihood class <cite>RateLikelihood</cite>, this will simultaneously estimate the local merger rate as well as the population distribution.n”,
“n”,
“This is created just as before.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “v-o0X0OiBaug”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“full_likelihood = gwpop.hyperpe.RateLikelihood(n”,
”    posteriors=posteriors, hyper_prior=full_model)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “<a href="#id13"><span class="problematic" id="id14">RkzUAuX4SNQ_</span></a>”,
“colab_type”: “text”</p>
</dd>
</dl>
<p>},
“cell_type”: “markdown”,
“source”: [</p>
<blockquote>
<div><p>“## Priorn”,
“n”,
“This is just a longer version of the previous.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “F2DXzB_KA8sR”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“full_priors = PriorDict()n”,
“n”,
“# raten”,
“fast_priors[‘rate’] = LogUniform(minimum=1e-20, maximum=1e20, latex_label=’$R$’)n”,
“# massn”,
“full_priors[‘alpha’] = Uniform(minimum=-4, maximum=12, latex_label=’$\\alpha$’)n”,
“full_priors[‘beta’] = Uniform(minimum=-4, maximum=12, latex_label=’$\\beta$’)n”,
“full_priors[‘mmin’] = Uniform(minimum=5, maximum=10, latex_label=’$m_{\\min}$’)n”,
“full_priors[‘mmax’] = Uniform(minimum=20, maximum=60, latex_label=’$m_{\\max}$’)n”,
“full_priors[‘lam’] = Uniform(minimum=0, maximum=1, latex_label=’$\\lambda_{m}$’)n”,
“full_priors[‘mpp’] = Uniform(minimum=20, maximum=50, latex_label=’$\\mu_{m}$’)n”,
“full_priors[‘sigpp’] = Uniform(minimum=0, maximum=10, latex_label=’$\\sigma_{m}$’)n”,
“# spin magnituden”,
“full_priors[‘amax’] = 1n”,
“full_priors[‘alpha_chi’] = Uniform(minimum=-4, maximum=12, latex_label=’$\\alpha_{\\chi}$’)n”,
“full_priors[‘beta_chi’] = Uniform(minimum=-4, maximum=12, latex_label=’$\\beta_{\\chi}$’)n”,
“# spin orientationn”,
“full_priors[‘xi_spin’] = Uniform(minimum=0, maximum=1, latex_label=’$\\xi$’)n”,
“full_priors[‘sigma_1’] = Uniform(minimum=0, maximum=4, latex_label=’$\\sigma{1}$’)n”,
“full_priors[‘sigma_2’] = Uniform(minimum=0, maximum=4, latex_label=’$\\sigma{2}$’)n”,
“# redshift evolutionn”,
“full_priors[‘lamb’] = Uniform(minimum=-25, maximum=25, latex_label=’$\\lambda_{z}$’)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><dl class="simple">
<dt>“metadata”: {</dt><dd><p>“id”: “PDd-8Z_WBXEs”,
“colab_type”: “code”,
“colab”: {}</p>
</dd>
</dl>
<p>},
“cell_type”: “code”,
“source”: [</p>
<blockquote>
<div><p>“full_likelihood.parameters.update(full_priors.sample())n”,
“full_likelihood.log_likelihood_ratio()n”,
“n”,
“full_result = run_sampler(n”,
”    likelihood=full_likelihood, priors=full_priors, sampler=’dynesty’,n”,
”    nlive=100)”</p>
</div></blockquote>
<p>],
“execution_count”: 0,
“outputs”: []</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="_autosummary/gwpopulation.vt.ResamplingVT.html" class="btn btn-neutral float-left" title="gwpopulation.vt.ResamplingVT" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Colm Talbot.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>